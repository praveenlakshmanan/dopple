input {
   file {
    path => ["/home/hduser/elasticsearch/logfiles/machinelogs/**/*.log"]
    start_position => beginning
    type=>"mclogs"

  }

}

filter {
  mutate
  {
    gsub => ["message", "\n", " "]
  }
 mutate
 {
    gsub => ["message", "\t", " "]
 }
 multiline
   {
        pattern => "^ "
        what => "previous"
   }

grok { match => [ "message", "%{TIME:log_time}\|%{WORD:Message_type}\|%{GREEDYDATA:Component}\|%{NUMBER:line_number}\| %{GREEDYDATA:log_message}"] 
	 match => [ "path" , "%{GREEDYDATA}/%{GREEDYDATA:loccode}/%{GREEDYDATA:_machine}\:%{DATE:logdate}.log"]
	
      	 break_on_match => false
}

 
#To check location is S or L
  if [loccode] == "S"  or [loccode] == "L" {
 ruby {   
        code => " temp = event['_machine'].split('_')
	          if  !temp.nil? || !temp.empty?
		  event['_machine'] = temp[0]
  	    end"
   } 
 }
 mutate {
    
    add_field => ["event_timestamp", "%{@timestamp}" ]
    replace => [ "log_time", "%{logdate} %{log_time}" ]
    # Remove the 'logdate' field since we don't need it anymore.
   lowercase=>["loccode"]
   remove => "logdate"
    	
  }
# to get all site details (site name, city and co-ordinates)
sitelocator{sitename => "loccode"  datafile=>"vendor/sitelocator/SiteDetails.csv"}
date {  locale=>"en"
	match => [ "log_time", "MM-dd-yyyy HH:mm:ss.SSS"] }
 
}

output {
stdout { codec => rubydebug }
elasticsearch{
        embedded => false
        host => "localhost"
	#host => "http://ec2-54-227-252-109.compute-1.amazonaws.com"
        port => "9300"
        cluster=>"test"
	manage_template=> false
	index=>"doppleml-%{loccode}-%{+YYYY.MM.dd}"
	#template=>"/home/hduser/elasticsearch/logstash-1.4.2/doppleML_template.json"
	template=>"/home/ubuntu/elkproject/logstash-1.4.2/doppleML_template.json"
	
     }

}

